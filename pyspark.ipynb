{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpmsiva/pysaprk-jupyter-note-book/blob/main/pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V8LjsrU4ECV",
        "outputId": "4d5cc26a-8900-4008-8b78-5ce83a728e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Ign:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,498 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,425 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [81.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.7 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.3 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,240 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,559 kB]\n",
            "Fetched 15.3 MB in 5s (2,795 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=871700026838d686825e088dbb5bf19ae2a910a68c1bf18eb619ef23bc59f940\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6c063fc0766e:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a38ed763a00>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XOSt82tN5S8f",
        "outputId": "00355047-a965-4512-afef-8dcdf24bc77b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdpf2EZd5yhU",
        "outputId": "165dbf79-30ec-4950-ab2e-02396f47b8ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|        _c0|      _c1|               _c2|        _c3|           _c4|        _c5|       _c6|          _c7|               _c8|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "|-122.050000|37.370000|         27.000000|3885.000000|    661.000000|1537.000000|606.000000|     6.608500|     344700.000000|\n",
            "|-118.300000|34.260000|         43.000000|1510.000000|    310.000000| 809.000000|277.000000|     3.599000|     176500.000000|\n",
            "|-117.810000|33.780000|         27.000000|3589.000000|    507.000000|1484.000000|495.000000|     5.793400|     270500.000000|\n",
            "|-118.360000|33.820000|         28.000000|  67.000000|     15.000000|  49.000000| 11.000000|     6.135900|     330000.000000|\n",
            "|-119.670000|36.330000|         19.000000|1241.000000|    244.000000| 850.000000|237.000000|     2.937500|      81700.000000|\n",
            "|-119.560000|36.510000|         37.000000|1018.000000|    213.000000| 663.000000|204.000000|     1.663500|      67000.000000|\n",
            "|-121.430000|38.630000|         43.000000|1009.000000|    225.000000| 604.000000|218.000000|     1.664100|      67000.000000|\n",
            "|-120.650000|35.480000|         19.000000|2310.000000|    471.000000|1341.000000|441.000000|     3.225000|     166900.000000|\n",
            "|-122.840000|38.400000|         15.000000|3080.000000|    617.000000|1446.000000|599.000000|     3.669600|     194400.000000|\n",
            "|-118.020000|34.080000|         31.000000|2402.000000|    632.000000|2830.000000|603.000000|     2.333300|     164200.000000|\n",
            "|-118.240000|33.980000|         45.000000| 972.000000|    249.000000|1288.000000|261.000000|     2.205400|     125000.000000|\n",
            "|-119.120000|35.850000|         37.000000| 736.000000|    166.000000| 564.000000|138.000000|     2.416700|      58300.000000|\n",
            "|-121.930000|37.250000|         36.000000|1089.000000|    182.000000| 535.000000|170.000000|     4.690000|     252600.000000|\n",
            "|-117.030000|32.970000|         16.000000|3936.000000|    694.000000|1935.000000|659.000000|     4.562500|     231200.000000|\n",
            "|-117.970000|33.730000|         27.000000|2097.000000|    325.000000|1217.000000|331.000000|     5.712100|     222500.000000|\n",
            "|-117.990000|33.810000|         42.000000| 161.000000|     40.000000| 157.000000| 50.000000|     2.200000|     153100.000000|\n",
            "|-120.810000|37.530000|         15.000000| 570.000000|    123.000000| 189.000000|107.000000|     1.875000|     181300.000000|\n",
            "|-121.200000|38.690000|         26.000000|3077.000000|    607.000000|1603.000000|595.000000|     2.717400|     137500.000000|\n",
            "|-118.880000|34.210000|         26.000000|1590.000000|    196.000000| 654.000000|199.000000|     6.585100|     300000.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df=spark.read.csv(\"sample_data/california_housing_test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2mpSxCF6txl",
        "outputId": "280f2cd5-3294-40de-a071-0a35d6ca3eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3001\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df.count())\n",
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnM-ckpl8cTZ"
      },
      "outputs": [],
      "source": [
        "def spark_shape(self):\n",
        "  return(self.count(),len(self.columns))\n",
        "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWlMOoDp80-K",
        "outputId": "d9f92714-5b1a-4081-a302-0edc329aa56d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3001, 9)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWs_44--9Iz8",
        "outputId": "3d7428e1-2224-4fe5-c09a-34a05eae8693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            "\n",
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
        "broadcastStates=spark.sparkContext.broadcast(states)\n",
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
        "df= spark.createDataFrame(data=data,schema=columns)\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLuntegI_i_V",
        "outputId": "1d8049d8-5790-4a6f-8962-822a0ae8a222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+-----+----------+\n",
            "|firstname|lastname|country|state|        _5|\n",
            "+---------+--------+-------+-----+----------+\n",
            "|    James|   Smith|    USA|   CA|California|\n",
            "|  Michael|    Rose|    USA|   NY|  New York|\n",
            "|   Robert|Williams|    USA|   CA|California|\n",
            "|    Maria|   Jones|    USA|   FL|   Florida|\n",
            "+---------+--------+-------+-----+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def state_converter(code):\n",
        "  return broadcastStates.value[code]\n",
        "\n",
        "result= df.rdd.map(lambda x: (x[0],x[1],x[2],x[3],state_converter(x[3]))).toDF(columns)\n",
        "result.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFSX46V7FXaI"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataDictionary = [\n",
        "        ('James',{'hair':'black','eye':'brown'}),\n",
        "        ('Michael',{'hair':'brown','eye':None}),\n",
        "        ('Robert',{'hair':'red','eye':'black'}),\n",
        "        ('Washington',{'hair':'red','eye':'grey'}),\n",
        "        ('Jefferson',{'hair':'red','eye':''})\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzLtNLgFe-x",
        "outputId": "60264b1c-c804-495e-928c-8f9b31d02c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> red}   |\n",
            "|Jefferson |{eye -> , hair -> red}       |\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df= spark.createDataFrame(data=dataDictionary, schema=[\"name\",\"properties\"])\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6zS7clxGUvd",
        "outputId": "d7080d9a-0266-4f78-c63d-b62293ee85cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> red}   |\n",
            "|Jefferson |{eye -> , hair -> red}       |\n",
            "+----------+-----------------------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,MapType\n",
        "schema= StructType([\n",
        "    StructField('name',StringType(),True),\n",
        "    StructField('properties',MapType(StringType(),StringType(),True))])\n",
        "df2=spark.createDataFrame(data=dataDictionary,schema=schema)\n",
        "df2.show(truncate=False)\n",
        "\n",
        "df2.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hALQQSuK6mj",
        "outputId": "0c968c34-4fa1-460b-eb21-e7305638b717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington|  red| grey|\n",
            "| Jefferson|  red|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.rdd.map(lambda x: (x.name,x.properties[\"hair\"],x.properties[\"eye\"])).toDF([\"name\",\"hair\",\"eye\"]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHGZMI3mNuu_",
        "outputId": "5eaceaac-ba4f-43eb-e6af-71d3c832d1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "accum=spark.sparkContext.accumulator(0)\n",
        "rdd= spark.sparkContext.parallelize([1,2,3,4,5])\n",
        "rdd.foreach(lambda x:accum.add(x))\n",
        "print(accum.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nds-wwWQOugu",
        "outputId": "e00eeb40-a746-416f-f82e-4de6fe3402c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n"
          ]
        }
      ],
      "source": [
        "def countfun(x):\n",
        "  global accum\n",
        "  accum+=x\n",
        "rdd.foreach(countfun)\n",
        "print(accum.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfP57HtNS_pu",
        "outputId": "a78992cc-407b-4fa6-8ad0-cc2dd5449428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|James    |Smith   |USA    |CA   |\n",
            "|Michael  |Rose    |USA    |NY   |\n",
            "|Robert   |Williams|USA    |CA   |\n",
            "|Maria    |Jones   |USA    |FL   |\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "\n",
        "# Column names\n",
        "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWbrm9HETSDg",
        "outputId": "4d5b62c9-9427-4d3f-c318-9260adee88fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(*columns).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1bSCKclT8Gd",
        "outputId": "1d1b31c4-2bdf-4c65-ce7b-15b886de406e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----------------------+-----+------+\n",
            "|name                  |state|gender|\n",
            "+----------------------+-----+------+\n",
            "|{James, NULL, Smith}  |OH   |M     |\n",
            "|{Anna, Rose, }        |NY   |F     |\n",
            "|{Julia, , Williams}   |OH   |F     |\n",
            "|{Maria, Anne, Jones}  |NY   |M     |\n",
            "|{Jen, Mary, Brown}    |NY   |M     |\n",
            "|{Mike, Mary, Williams}|OH   |M     |\n",
            "+----------------------+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema = StructType([\n",
        "    StructField('name', StructType([\n",
        "         StructField('firstname', StringType(), True),\n",
        "         StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "         ])),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True)\n",
        "     ])\n",
        "\n",
        "\n",
        "data = [((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
        "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
        "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
        "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
        "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
        "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
        "        ]\n",
        "\n",
        "df2 = spark.createDataFrame(data = data, schema = schema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o010rksjUU3G",
        "outputId": "643481d2-2cb9-4eea-9606-11d9812914d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+-----+------+\n",
            "|firstname|middlename|lastname|state|gender|\n",
            "+---------+----------+--------+-----+------+\n",
            "|James    |NULL      |Smith   |OH   |M     |\n",
            "|Anna     |Rose      |        |NY   |F     |\n",
            "|Julia    |          |Williams|OH   |F     |\n",
            "|Maria    |Anne      |Jones   |NY   |M     |\n",
            "|Jen      |Mary      |Brown   |NY   |M     |\n",
            "|Mike     |Mary      |Williams|OH   |M     |\n",
            "+---------+----------+--------+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.select('name.*',\"state\",\"gender\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDHIFs0yrNnh"
      },
      "outputs": [],
      "source": [
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wct4zIOgrS01"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark= SparkSession.builder.appName(\"siva\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkc74ZeGtk3a",
        "outputId": "8fd95623-b703-403f-8e38-203bd22a9e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|dob       |gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|James    |          |Smith   |1991-04-01|M     |3000  |\n",
            "|Michael  |Rose      |        |2000-05-19|M     |4000  |\n",
            "|Robert   |          |Williams|1978-09-05|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df= spark.createDataFrame(data=data,schema=columns)\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOkbxyptuMLM",
        "outputId": "18a88e8c-ec69-4189-fb1f-ebcd909b11ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8iIyfo_urLg",
        "outputId": "ad377387-1f7c-4907-96d6-2d44ea502ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6j21ISDwEIp",
        "outputId": "e21f0f5c-c65b-4f8c-8947-cb9359a90bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|300000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|400000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|400000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|400000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|  -100|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"salary\",col(\"salary\")*100).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqLJ24jzwWPR",
        "outputId": "c7c7baa5-b05c-4b56-e6a1-26bee0dfd950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+----------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|new_salary|\n",
            "+---------+----------+--------+----------+------+------+----------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|     36000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|     48000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|     48000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|     48000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|       -12|\n",
            "+---------+----------+--------+----------+------+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"new_salary\",col(\"salary\")*12).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZY9NPRew6ZE",
        "outputId": "9e6c0229-9195-4a44-efe9-3863dbb4a13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+-------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|country|\n",
            "+---------+----------+--------+----------+------+------+-------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|  india|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|  india|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|  india|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|  india|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|  india|\n",
            "+---------+----------+--------+----------+------+------+-------+\n",
            "\n",
            "+---------+----------+--------+----------+------+------+-------+-----+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|country|state|\n",
            "+---------+----------+--------+----------+------+------+-------+-----+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|  india|   TN|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|  india|   TN|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|  india|   TN|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|  india|   TN|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|  india|   TN|\n",
            "+---------+----------+--------+----------+------+------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df.withColumn(\"country\",lit(\"india\")).show()\n",
        "df.withColumn(\"country\",lit(\"india\"))\\\n",
        "  .withColumn(\"state\",lit(\"TN\"))\\\n",
        "  .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XznYXrYDyLu7",
        "outputId": "10b40e4b-78e8-4da2-ab25-36b43e83806e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+---+------+\n",
            "|firstname|middlename|lastname|       dob|sex|salary|\n",
            "+---------+----------+--------+----------+---+------+\n",
            "|    James|          |   Smith|1991-04-01|  M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|  M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|  M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|  F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|  F|    -1|\n",
            "+---------+----------+--------+----------+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumnRenamed(\"gender\",\"sex\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZxms8wKzOhw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
        "\n",
        "schema= StructType([\n",
        "    StructField('fname',StructType([\n",
        "        StructField('fname',StringType(),True),\n",
        "        StructField('mname',StringType(),True),\n",
        "        StructField('lname',StringType(),True),\n",
        "        ])),\n",
        "    StructField('dob',StringType(),True),\n",
        "    StructField('gender',StringType(),True),\n",
        "    StructField('salary',StringType(),True),\n",
        "    ])\n",
        "\n",
        "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
        "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
        "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
        "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
        "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNioRRFL5GAg",
        "outputId": "6eeaeb65-a1de-4305-9673-c9511fb30d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+----------+------+------+\n",
            "|               fname|       dob|gender|salary|\n",
            "+--------------------+----------+------+------+\n",
            "|    {James, , Smith}|1991-04-01|     M|  3000|\n",
            "|   {Michael, Rose, }|2000-05-19|     M|  4000|\n",
            "|{Robert, , Williams}|1978-09-05|     M|  4000|\n",
            "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|\n",
            "|  {Jen, Mary, Brown}|1980-02-17|     F|    -1|\n",
            "+--------------------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df= spark.createDataFrame(data=dataDF,schema=schema).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "taaT1aZb44Lp",
        "outputId": "9521b7fc-dafc-4a7d-a051-4a6731b7ae8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path=os.getcwd()\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVz56U2P_Y4F"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "spark = SparkSession.builder.appName(\"siva\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\", \"Sales\", 3000), \\\n",
        "    (\"Michael\", \"Sales\", 4600), \\\n",
        "    (\"Robert\", \"Sales\", 4100), \\\n",
        "    (\"Maria\", \"Finance\", 3000), \\\n",
        "    (\"James\", \"Sales\", 3000), \\\n",
        "    (\"Scott\", \"Finance\", 3300), \\\n",
        "    (\"Jen\", \"Finance\", 3900), \\\n",
        "    (\"Jeff\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000), \\\n",
        "    (\"Saif\", \"Sales\", 4100) \\\n",
        "  ]\n",
        "\n",
        "# Create DataFrame\n",
        "column= [\"employee_name\", \"department\", \"salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data=data, schema=column)\n",
        "df.show()x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEubfDFO_zzw",
        "outputId": "5f0a5053-e437-4b01-c740-2d19053c6fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|        James|     Sales|  3000|\n",
            "|      Michael|     Sales|  4600|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|        James|     Sales|  3000|\n",
            "|        Scott|   Finance|  3300|\n",
            "|          Jen|   Finance|  3900|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disdf=df.distinct()\n",
        "print(disdf.count())\n",
        "\n",
        "disdf.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiLsksGOBrC-",
        "outputId": "4aca0b24-ddad-4f48-88ba-a5aafc89c715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|      Michael|     Sales|  4600|\n",
            "|        James|     Sales|  3000|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|          Jen|   Finance|  3900|\n",
            "|        Scott|   Finance|  3300|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dupdf=df.dropDuplicates()\n",
        "print(dupdf.count())\n",
        "\n",
        "dupdf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsMfPvWgEkCl",
        "outputId": "cea55179-a7fe-4b1f-f8f8-b269405ba6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|      Michael|     Sales|  4600|\n",
            "|        James|     Sales|  3000|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|          Jen|   Finance|  3900|\n",
            "|        Scott|   Finance|  3300|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLZZHBgrplhrcxyL1SyH7V",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}