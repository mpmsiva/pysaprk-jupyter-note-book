{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpmsiva/pysaprk-jupyter-note-book/blob/main/pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "9V8LjsrU4ECV",
        "outputId": "f2553db7-42aa-4938-f3c7-eafd00a5a68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connecting to cloud.r-project.o\u001b[0m\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\u001b[0m\r                                                                               \rIgn:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connected to ppa.\u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Waiting for heade\u001b[0m\r                                                                               \rHit:5 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connected to ppa.\u001b[0m\u001b[33m\r0% [Waiting for headers] [Connecting to cloud.r-project.org] [Connected to ppa.\u001b[0m\r                                                                               \rHit:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c2fe4e63a90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://cbe3baed5ca4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XOSt82tN5S8f",
        "outputId": "00355047-a965-4512-afef-8dcdf24bc77b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mdpf2EZd5yhU",
        "outputId": "165dbf79-30ec-4950-ab2e-02396f47b8ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|        _c0|      _c1|               _c2|        _c3|           _c4|        _c5|       _c6|          _c7|               _c8|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "|-122.050000|37.370000|         27.000000|3885.000000|    661.000000|1537.000000|606.000000|     6.608500|     344700.000000|\n",
            "|-118.300000|34.260000|         43.000000|1510.000000|    310.000000| 809.000000|277.000000|     3.599000|     176500.000000|\n",
            "|-117.810000|33.780000|         27.000000|3589.000000|    507.000000|1484.000000|495.000000|     5.793400|     270500.000000|\n",
            "|-118.360000|33.820000|         28.000000|  67.000000|     15.000000|  49.000000| 11.000000|     6.135900|     330000.000000|\n",
            "|-119.670000|36.330000|         19.000000|1241.000000|    244.000000| 850.000000|237.000000|     2.937500|      81700.000000|\n",
            "|-119.560000|36.510000|         37.000000|1018.000000|    213.000000| 663.000000|204.000000|     1.663500|      67000.000000|\n",
            "|-121.430000|38.630000|         43.000000|1009.000000|    225.000000| 604.000000|218.000000|     1.664100|      67000.000000|\n",
            "|-120.650000|35.480000|         19.000000|2310.000000|    471.000000|1341.000000|441.000000|     3.225000|     166900.000000|\n",
            "|-122.840000|38.400000|         15.000000|3080.000000|    617.000000|1446.000000|599.000000|     3.669600|     194400.000000|\n",
            "|-118.020000|34.080000|         31.000000|2402.000000|    632.000000|2830.000000|603.000000|     2.333300|     164200.000000|\n",
            "|-118.240000|33.980000|         45.000000| 972.000000|    249.000000|1288.000000|261.000000|     2.205400|     125000.000000|\n",
            "|-119.120000|35.850000|         37.000000| 736.000000|    166.000000| 564.000000|138.000000|     2.416700|      58300.000000|\n",
            "|-121.930000|37.250000|         36.000000|1089.000000|    182.000000| 535.000000|170.000000|     4.690000|     252600.000000|\n",
            "|-117.030000|32.970000|         16.000000|3936.000000|    694.000000|1935.000000|659.000000|     4.562500|     231200.000000|\n",
            "|-117.970000|33.730000|         27.000000|2097.000000|    325.000000|1217.000000|331.000000|     5.712100|     222500.000000|\n",
            "|-117.990000|33.810000|         42.000000| 161.000000|     40.000000| 157.000000| 50.000000|     2.200000|     153100.000000|\n",
            "|-120.810000|37.530000|         15.000000| 570.000000|    123.000000| 189.000000|107.000000|     1.875000|     181300.000000|\n",
            "|-121.200000|38.690000|         26.000000|3077.000000|    607.000000|1603.000000|595.000000|     2.717400|     137500.000000|\n",
            "|-118.880000|34.210000|         26.000000|1590.000000|    196.000000| 654.000000|199.000000|     6.585100|     300000.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df=spark.read.csv(\"sample_data/california_housing_test.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2mpSxCF6txl",
        "outputId": "280f2cd5-3294-40de-a071-0a35d6ca3eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3001\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df.count())\n",
        "len(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnM-ckpl8cTZ"
      },
      "outputs": [],
      "source": [
        "def spark_shape(self):\n",
        "  return(self.count(),len(self.columns))\n",
        "pyspark.sql.dataframe.DataFrame.shape = spark_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWlMOoDp80-K",
        "outputId": "d9f92714-5b1a-4081-a302-0edc329aa56d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3001, 9)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWs_44--9Iz8",
        "outputId": "3d7428e1-2224-4fe5-c09a-34a05eae8693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            "\n",
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
        "broadcastStates=spark.sparkContext.broadcast(states)\n",
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
        "df= spark.createDataFrame(data=data,schema=columns)\n",
        "df.printSchema()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLuntegI_i_V",
        "outputId": "1d8049d8-5790-4a6f-8962-822a0ae8a222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+-----+----------+\n",
            "|firstname|lastname|country|state|        _5|\n",
            "+---------+--------+-------+-----+----------+\n",
            "|    James|   Smith|    USA|   CA|California|\n",
            "|  Michael|    Rose|    USA|   NY|  New York|\n",
            "|   Robert|Williams|    USA|   CA|California|\n",
            "|    Maria|   Jones|    USA|   FL|   Florida|\n",
            "+---------+--------+-------+-----+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def state_converter(code):\n",
        "  return broadcastStates.value[code]\n",
        "\n",
        "result= df.rdd.map(lambda x: (x[0],x[1],x[2],x[3],state_converter(x[3]))).toDF(columns)\n",
        "result.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFSX46V7FXaI"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataDictionary = [\n",
        "        ('James',{'hair':'black','eye':'brown'}),\n",
        "        ('Michael',{'hair':'brown','eye':None}),\n",
        "        ('Robert',{'hair':'red','eye':'black'}),\n",
        "        ('Washington',{'hair':'red','eye':'grey'}),\n",
        "        ('Jefferson',{'hair':'red','eye':''})\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apzLtNLgFe-x",
        "outputId": "60264b1c-c804-495e-928c-8f9b31d02c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n",
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> red}   |\n",
            "|Jefferson |{eye -> , hair -> red}       |\n",
            "+----------+-----------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df= spark.createDataFrame(data=dataDictionary, schema=[\"name\",\"properties\"])\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6zS7clxGUvd",
        "outputId": "d7080d9a-0266-4f78-c63d-b62293ee85cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------------------------+\n",
            "|name      |properties                   |\n",
            "+----------+-----------------------------+\n",
            "|James     |{eye -> brown, hair -> black}|\n",
            "|Michael   |{eye -> NULL, hair -> brown} |\n",
            "|Robert    |{eye -> black, hair -> red}  |\n",
            "|Washington|{eye -> grey, hair -> red}   |\n",
            "|Jefferson |{eye -> , hair -> red}       |\n",
            "+----------+-----------------------------+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- properties: map (nullable = true)\n",
            " |    |-- key: string\n",
            " |    |-- value: string (valueContainsNull = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,MapType\n",
        "schema= StructType([\n",
        "    StructField('name',StringType(),True),\n",
        "    StructField('properties',MapType(StringType(),StringType(),True))])\n",
        "df2=spark.createDataFrame(data=dataDictionary,schema=schema)\n",
        "df2.show(truncate=False)\n",
        "\n",
        "df2.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hALQQSuK6mj",
        "outputId": "0c968c34-4fa1-460b-eb21-e7305638b717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----+-----+\n",
            "|      name| hair|  eye|\n",
            "+----------+-----+-----+\n",
            "|     James|black|brown|\n",
            "|   Michael|brown| NULL|\n",
            "|    Robert|  red|black|\n",
            "|Washington|  red| grey|\n",
            "| Jefferson|  red|     |\n",
            "+----------+-----+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.rdd.map(lambda x: (x.name,x.properties[\"hair\"],x.properties[\"eye\"])).toDF([\"name\",\"hair\",\"eye\"]).show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHGZMI3mNuu_",
        "outputId": "5eaceaac-ba4f-43eb-e6af-71d3c832d1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "accum=spark.sparkContext.accumulator(0)\n",
        "rdd= spark.sparkContext.parallelize([1,2,3,4,5])\n",
        "rdd.foreach(lambda x:accum.add(x))\n",
        "print(accum.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nds-wwWQOugu",
        "outputId": "e00eeb40-a746-416f-f82e-4de6fe3402c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35\n"
          ]
        }
      ],
      "source": [
        "def countfun(x):\n",
        "  global accum\n",
        "  accum+=x\n",
        "rdd.foreach(countfun)\n",
        "print(accum.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfP57HtNS_pu",
        "outputId": "a78992cc-407b-4fa6-8ad0-cc2dd5449428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|James    |Smith   |USA    |CA   |\n",
            "|Michael  |Rose    |USA    |NY   |\n",
            "|Robert   |Williams|USA    |CA   |\n",
            "|Maria    |Jones   |USA    |FL   |\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
        "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
        "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
        "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
        "  ]\n",
        "\n",
        "# Column names\n",
        "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWbrm9HETSDg",
        "outputId": "4d5b62c9-9427-4d3f-c318-9260adee88fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------+-------+-----+\n",
            "|firstname|lastname|country|state|\n",
            "+---------+--------+-------+-----+\n",
            "|    James|   Smith|    USA|   CA|\n",
            "|  Michael|    Rose|    USA|   NY|\n",
            "|   Robert|Williams|    USA|   CA|\n",
            "|    Maria|   Jones|    USA|   FL|\n",
            "+---------+--------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select(*columns).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1bSCKclT8Gd",
        "outputId": "1d1b31c4-2bdf-4c65-ce7b-15b886de406e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----------------------+-----+------+\n",
            "|name                  |state|gender|\n",
            "+----------------------+-----+------+\n",
            "|{James, NULL, Smith}  |OH   |M     |\n",
            "|{Anna, Rose, }        |NY   |F     |\n",
            "|{Julia, , Williams}   |OH   |F     |\n",
            "|{Maria, Anne, Jones}  |NY   |M     |\n",
            "|{Jen, Mary, Brown}    |NY   |M     |\n",
            "|{Mike, Mary, Williams}|OH   |M     |\n",
            "+----------------------+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema = StructType([\n",
        "    StructField('name', StructType([\n",
        "         StructField('firstname', StringType(), True),\n",
        "         StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "         ])),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True)\n",
        "     ])\n",
        "\n",
        "\n",
        "data = [((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
        "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
        "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
        "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
        "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
        "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
        "        ]\n",
        "\n",
        "df2 = spark.createDataFrame(data = data, schema = schema)\n",
        "df2.printSchema()\n",
        "df2.show(truncate=False)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o010rksjUU3G",
        "outputId": "643481d2-2cb9-4eea-9606-11d9812914d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+-----+------+\n",
            "|firstname|middlename|lastname|state|gender|\n",
            "+---------+----------+--------+-----+------+\n",
            "|James    |NULL      |Smith   |OH   |M     |\n",
            "|Anna     |Rose      |        |NY   |F     |\n",
            "|Julia    |          |Williams|OH   |F     |\n",
            "|Maria    |Anne      |Jones   |NY   |M     |\n",
            "|Jen      |Mary      |Brown   |NY   |M     |\n",
            "|Mike     |Mary      |Williams|OH   |M     |\n",
            "+---------+----------+--------+-----+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.select('name.*',\"state\",\"gender\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDHIFs0yrNnh"
      },
      "outputs": [],
      "source": [
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wct4zIOgrS01"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark= SparkSession.builder.appName(\"siva\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkc74ZeGtk3a",
        "outputId": "8fd95623-b703-403f-8e38-203bd22a9e4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|dob       |gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|James    |          |Smith   |1991-04-01|M     |3000  |\n",
            "|Michael  |Rose      |        |2000-05-19|M     |4000  |\n",
            "|Robert   |          |Williams|1978-09-05|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |1967-12-01|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |1980-02-17|F     |-1    |\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df= spark.createDataFrame(data=data,schema=columns)\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOkbxyptuMLM",
        "outputId": "18a88e8c-ec69-4189-fb1f-ebcd909b11ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8iIyfo_urLg",
        "outputId": "ad377387-1f7c-4907-96d6-2d44ea502ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.withColumn(\"salary\",col(\"salary\").cast(\"Integer\")).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6j21ISDwEIp",
        "outputId": "e21f0f5c-c65b-4f8c-8947-cb9359a90bdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|300000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|400000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|400000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|400000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|  -100|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"salary\",col(\"salary\")*100).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqLJ24jzwWPR",
        "outputId": "c7c7baa5-b05c-4b56-e6a1-26bee0dfd950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+----------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|new_salary|\n",
            "+---------+----------+--------+----------+------+------+----------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|     36000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|     48000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|     48000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|     48000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|       -12|\n",
            "+---------+----------+--------+----------+------+------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumn(\"new_salary\",col(\"salary\")*12).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZY9NPRew6ZE",
        "outputId": "9e6c0229-9195-4a44-efe9-3863dbb4a13d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+------+------+-------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|country|\n",
            "+---------+----------+--------+----------+------+------+-------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|  india|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|  india|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|  india|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|  india|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|  india|\n",
            "+---------+----------+--------+----------+------+------+-------+\n",
            "\n",
            "+---------+----------+--------+----------+------+------+-------+-----+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|country|state|\n",
            "+---------+----------+--------+----------+------+------+-------+-----+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|  india|   TN|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|  india|   TN|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|  india|   TN|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|  india|   TN|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|  india|   TN|\n",
            "+---------+----------+--------+----------+------+------+-------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df.withColumn(\"country\",lit(\"india\")).show()\n",
        "df.withColumn(\"country\",lit(\"india\"))\\\n",
        "  .withColumn(\"state\",lit(\"TN\"))\\\n",
        "  .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XznYXrYDyLu7",
        "outputId": "10b40e4b-78e8-4da2-ab25-36b43e83806e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+----------+--------+----------+---+------+\n",
            "|firstname|middlename|lastname|       dob|sex|salary|\n",
            "+---------+----------+--------+----------+---+------+\n",
            "|    James|          |   Smith|1991-04-01|  M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|  M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|  M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|  F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|  F|    -1|\n",
            "+---------+----------+--------+----------+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.withColumnRenamed(\"gender\",\"sex\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZxms8wKzOhw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
        "\n",
        "schema= StructType([\n",
        "    StructField('fname',StructType([\n",
        "        StructField('fname',StringType(),True),\n",
        "        StructField('mname',StringType(),True),\n",
        "        StructField('lname',StringType(),True),\n",
        "        ])),\n",
        "    StructField('dob',StringType(),True),\n",
        "    StructField('gender',StringType(),True),\n",
        "    StructField('salary',StringType(),True),\n",
        "    ])\n",
        "\n",
        "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
        "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
        "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
        "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
        "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNioRRFL5GAg",
        "outputId": "6eeaeb65-a1de-4305-9673-c9511fb30d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+----------+------+------+\n",
            "|               fname|       dob|gender|salary|\n",
            "+--------------------+----------+------+------+\n",
            "|    {James, , Smith}|1991-04-01|     M|  3000|\n",
            "|   {Michael, Rose, }|2000-05-19|     M|  4000|\n",
            "|{Robert, , Williams}|1978-09-05|     M|  4000|\n",
            "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|\n",
            "|  {Jen, Mary, Brown}|1980-02-17|     F|    -1|\n",
            "+--------------------+----------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df= spark.createDataFrame(data=dataDF,schema=schema).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "taaT1aZb44Lp",
        "outputId": "9521b7fc-dafc-4a7d-a051-4a6731b7ae8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path=os.getcwd()\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVz56U2P_Y4F"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "spark = SparkSession.builder.appName(\"siva\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(\"James\", \"Sales\", 3000), \\\n",
        "    (\"Michael\", \"Sales\", 4600), \\\n",
        "    (\"Robert\", \"Sales\", 4100), \\\n",
        "    (\"Maria\", \"Finance\", 3000), \\\n",
        "    (\"James\", \"Sales\", 3000), \\\n",
        "    (\"Scott\", \"Finance\", 3300), \\\n",
        "    (\"Jen\", \"Finance\", 3900), \\\n",
        "    (\"Jeff\", \"Marketing\", 3000), \\\n",
        "    (\"Kumar\", \"Marketing\", 2000), \\\n",
        "    (\"Saif\", \"Sales\", 4100) \\\n",
        "  ]\n",
        "\n",
        "# Create DataFrame\n",
        "column= [\"employee_name\", \"department\", \"salary\"]\n",
        "\n",
        "df = spark.createDataFrame(data=data, schema=column)\n",
        "df.show()x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEubfDFO_zzw",
        "outputId": "5f0a5053-e437-4b01-c740-2d19053c6fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|        James|     Sales|  3000|\n",
            "|      Michael|     Sales|  4600|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|        James|     Sales|  3000|\n",
            "|        Scott|   Finance|  3300|\n",
            "|          Jen|   Finance|  3900|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disdf=df.distinct()\n",
        "print(disdf.count())\n",
        "\n",
        "disdf.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiLsksGOBrC-",
        "outputId": "4aca0b24-ddad-4f48-88ba-a5aafc89c715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|      Michael|     Sales|  4600|\n",
            "|        James|     Sales|  3000|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|          Jen|   Finance|  3900|\n",
            "|        Scott|   Finance|  3300|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dupdf=df.dropDuplicates()\n",
        "print(dupdf.count())\n",
        "\n",
        "dupdf.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsMfPvWgEkCl",
        "outputId": "cea55179-a7fe-4b1f-f8f8-b269405ba6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "+-------------+----------+------+\n",
            "|employee_name|department|salary|\n",
            "+-------------+----------+------+\n",
            "|      Michael|     Sales|  4600|\n",
            "|        James|     Sales|  3000|\n",
            "|       Robert|     Sales|  4100|\n",
            "|        Maria|   Finance|  3000|\n",
            "|          Jen|   Finance|  3900|\n",
            "|        Scott|   Finance|  3300|\n",
            "|        Kumar| Marketing|  2000|\n",
            "|         Jeff| Marketing|  3000|\n",
            "|         Saif|     Sales|  4100|\n",
            "+-------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "# Create DataFrame df1 with columns name, and id\n",
        "data = [(\"James\",34), (\"Michael\",56), \\\n",
        "        (\"Robert\",30), (\"Maria\",24) ]\n",
        "\n",
        "df1 = spark.createDataFrame(data = data, schema=[\"name\",\"id\"])\n",
        "df1.printSchema()\n",
        "\n",
        "# Create DataFrame df2 with columns name and id\n",
        "data2=[(34,\"James\"),(45,\"Maria\"), \\\n",
        "       (45,\"Jen\"),(34,\"Jeff\")]\n",
        "\n",
        "df2 = spark.createDataFrame(data = data2, schema = [\"id\",\"name\"])\n",
        "df2.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOKLcrD6XUBI",
        "outputId": "459e118f-5b3d-4f51-f1a8-6cbe7905ef98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n",
            "root\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df1.unionByName(df2)\n",
        "df3.show()\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RCHWMnsXZUW",
        "outputId": "92ef270b-6fb3-4b17-d1ca-2b4d2c9157d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---+\n",
            "|   name| id|\n",
            "+-------+---+\n",
            "|  James| 34|\n",
            "|Michael| 56|\n",
            "| Robert| 30|\n",
            "|  Maria| 24|\n",
            "|  James| 34|\n",
            "|  Maria| 45|\n",
            "|    Jen| 45|\n",
            "|   Jeff| 34|\n",
            "+-------+---+\n",
            "\n",
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame([[5, 2, 6]], [\"col0\", \"col1\", \"col2\"])\n",
        "df2 = spark.createDataFrame([[6, 7, 3]], [\"col1\", \"col2\", \"col3\"])\n",
        "\n",
        "\n",
        "df1.show()\n",
        "df2.show()\n",
        "# Using allowMissingColumns\n",
        "df3 = df1.unionByName(df2, allowMissingColumns=True)\n",
        "df3.printSchema\n",
        "df3.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8p9yvNgWYR5Z",
        "outputId": "078a9c78-a776-4122-e71c-1a4c093af9a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+\n",
            "|col0|col1|col2|\n",
            "+----+----+----+\n",
            "|   5|   2|   6|\n",
            "+----+----+----+\n",
            "\n",
            "+----+----+----+\n",
            "|col1|col2|col3|\n",
            "+----+----+----+\n",
            "|   6|   7|   3|\n",
            "+----+----+----+\n",
            "\n",
            "+----+----+----+----+\n",
            "|col0|col1|col2|col3|\n",
            "+----+----+----+----+\n",
            "|   5|   2|   6|NULL|\n",
            "|NULL|   6|   7|   3|\n",
            "+----+----+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "            .appName('SparkByExamples.com') \\\n",
        "            .getOrCreate()\n",
        "\n",
        "# Prepare Data\n",
        "simpleData = ((\"Java\",4000,5), \\\n",
        "    (\"Python\", 4600,10),  \\\n",
        "    (\"Scala\", 4100,15),   \\\n",
        "    (\"Scala\", 4500,15),   \\\n",
        "    (\"PHP\", 3000,20),  \\\n",
        "  )\n",
        "columns= [\"CourseName\", \"fee\", \"discount\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKr2fPYWaxRH",
        "outputId": "196485a9-953d-45b2-ebf8-d84c90394232"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CourseName: string (nullable = true)\n",
            " |-- fee: long (nullable = true)\n",
            " |-- discount: long (nullable = true)\n",
            "\n",
            "+----------+----+--------+\n",
            "|CourseName|fee |discount|\n",
            "+----------+----+--------+\n",
            "|Java      |4000|5       |\n",
            "|Python    |4600|10      |\n",
            "|Scala     |4100|15      |\n",
            "|Scala     |4500|15      |\n",
            "|PHP       |3000|20      |\n",
            "+----------+----+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "            .appName('SparkByExamples.com') \\\n",
        "            .getOrCreate()\n",
        "\n",
        "# Prepare Data\n",
        "simpleData = ((\"Java\",4000,5), \\\n",
        "    (\"Python\", 4600,10),  \\\n",
        "    (\"Scala\", 4100,15),   \\\n",
        "    (\"Scala\", 4500,15),   \\\n",
        "    (\"PHP\", 3000,20),  \\\n",
        "  )\n",
        "columns= [\"CourseName\", \"fee\", \"discount\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kd2hJxJcFhJ",
        "outputId": "61bc5b81-0673-46ee-d510-ef57f6ee3f72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CourseName: string (nullable = true)\n",
            " |-- fee: long (nullable = true)\n",
            " |-- discount: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import upper\n",
        "def to_upper_str_columns(df):\n",
        "    return df.withColumn(\"CourseName\",upper(df.CourseName))\n",
        "\n",
        "# Custom transformation 2\n",
        "def reduce_price(df,reduceBy):\n",
        "    return df.withColumn(\"new_fee\",df.fee - reduceBy)\n",
        "\n",
        "# Custom transformation 3\n",
        "def apply_discount(df):\n",
        "    return df.withColumn(\"discounted_fee\",  \\\n",
        "             df.new_fee - (df.new_fee * df.discount) / 100)\n",
        "\n",
        "# transform() usage\n",
        "df2 = df.transform(to_upper_str_columns) \\\n",
        "        .transform(reduce_price,1000) \\\n",
        "        .transform(apply_discount)\n",
        "\n",
        "df2.show()\n",
        "\n",
        "# Create DataFrame with Array\n",
        "data = [\n",
        " (\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]),\n",
        " (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]),\n",
        " (\"Robert,,Williams\",[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"])\n",
        "]\n",
        "df = spark.createDataFrame(data=data,schema=[\"Name\",\"Languages1\",\"Languages2\"])\n",
        "df.printSchema()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz0bHyLDddRJ",
        "outputId": "844a777c-f692-47bd-fe01-43ffd3ac7a9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+--------+-------+--------------+\n",
            "|CourseName| fee|discount|new_fee|discounted_fee|\n",
            "+----------+----+--------+-------+--------------+\n",
            "|      JAVA|4000|       5|   3000|        2850.0|\n",
            "|    PYTHON|4600|      10|   3600|        3240.0|\n",
            "|     SCALA|4100|      15|   3100|        2635.0|\n",
            "|     SCALA|4500|      15|   3500|        2975.0|\n",
            "|       PHP|3000|      20|   2000|        1600.0|\n",
            "+----------+----+--------+-------+--------------+\n",
            "\n",
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Languages1: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- Languages2: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+----------------+------------------+---------------+\n",
            "|            Name|        Languages1|     Languages2|\n",
            "+----------------+------------------+---------------+\n",
            "|    James,,Smith|[Java, Scala, C++]|  [Spark, Java]|\n",
            "|   Michael,Rose,|[Spark, Java, C++]|  [Spark, Java]|\n",
            "|Robert,,Williams|      [CSharp, VB]|[Spark, Python]|\n",
            "+----------------+------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "columns = [\"Seqno\",\"Name\"]\n",
        "data = [(\"1\", \"john jones\"),\n",
        "    (\"2\", \"tracey smith\"),\n",
        "    (\"3\", \"amy sanders\")]\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-TQSCPnfMNl",
        "outputId": "4cc65084-7fc8-41d0-f2fd-160fc5374039"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+\n",
            "|Seqno|Name        |\n",
            "+-----+------------+\n",
            "|1    |john jones  |\n",
            "|2    |tracey smith|\n",
            "|3    |amy sanders |\n",
            "+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function using withColumn\n",
        "from pyspark.sql.functions import upper\n",
        "df.withColumn(\"Upper_Name\", upper(df.Name)) \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vblVIcT_fm2I",
        "outputId": "6c8c2815-4599-4c30-a212-d464b4bfd654"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name|  Upper_Name|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply function using select\n",
        "df.select(\"Seqno\",\"Name\", upper(df.Name)) \\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG_gl3okfq8S",
        "outputId": "8394f3e7-b4b8-4500-d129-3a7197aaea59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name| upper(Name)|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"TAB\")\n",
        "spark.sql(\"select Seqno, Name, UPPER(Name) from TAB\") \\\n",
        "     .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmr6dvLEftfc",
        "outputId": "f99ef761-82a6-4d8f-ddd5-50f684d83f39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+------------+\n",
            "|Seqno|        Name| upper(Name)|\n",
            "+-----+------------+------------+\n",
            "|    1|  john jones|  JOHN JONES|\n",
            "|    2|tracey smith|TRACEY SMITH|\n",
            "|    3| amy sanders| AMY SANDERS|\n",
            "+-----+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upperCase(str):\n",
        "    return str.upper()\n",
        "\n",
        "# Convert function to udf\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "upperCaseUDF = udf(lambda x:upperCase(x),StringType())\n",
        "\n",
        "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
        "  .show(truncate=False)\n",
        "\n",
        "# Custom UDF with select()\n",
        "df.select(col(\"Seqno\"), \\\n",
        "    upperCaseUDF(col(\"Name\")).alias(\"Name\") ) \\\n",
        "   .show(truncate=False)\n",
        "\n",
        "# Custom UDF with sql()\n",
        "spark.udf.register(\"upperCaseUDF\", upperCaseUDF)\n",
        "df.createOrReplaceTempView(\"TAB\")\n",
        "spark.sql(\"select Seqno, Name, upperCaseUDF(Name) from TAB\") \\\n",
        "     .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQpnydvAfwSS",
        "outputId": "aea599d1-fcda-43a2-e39c-b033ab19cc2d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+-------------+\n",
            "|Seqno|Name        |Cureated Name|\n",
            "+-----+------------+-------------+\n",
            "|1    |john jones  |JOHN JONES   |\n",
            "|2    |tracey smith|TRACEY SMITH |\n",
            "|3    |amy sanders |AMY SANDERS  |\n",
            "+-----+------------+-------------+\n",
            "\n",
            "+-----+------------+\n",
            "|Seqno|Name        |\n",
            "+-----+------------+\n",
            "|1    |JOHN JONES  |\n",
            "|2    |TRACEY SMITH|\n",
            "|3    |AMY SANDERS |\n",
            "+-----+------------+\n",
            "\n",
            "+-----+------------+------------------+\n",
            "|Seqno|        Name|upperCaseUDF(Name)|\n",
            "+-----+------------+------------------+\n",
            "|    1|  john jones|        JOHN JONES|\n",
            "|    2|tracey smith|      TRACEY SMITH|\n",
            "|    3| amy sanders|       AMY SANDERS|\n",
            "+-----+------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import pyspark.pandas as ps\n",
        "import numpy as np\n",
        "\n",
        "technologies = ({\n",
        "    'Fee' :[20000,25000,30000,22000,np.NaN],\n",
        "    'Discount':[1000,2500,1500,1200,3000]\n",
        "               })\n",
        "# Create a DataFrame\n",
        "psdf = ps.DataFrame(technologies)\n",
        "print(psdf)\n",
        "\n",
        "def add(data):\n",
        "   return data[0] + data[1]\n",
        "\n",
        "addDF = psdf.apply(add,axis=1)\n",
        "print(addDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVEDIF3YgIrb",
        "outputId": "144da664-15b2-49f3-d74c-f249b9603a23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Fee  Discount\n",
            "0  20000.0      1000\n",
            "1  25000.0      2500\n",
            "2  30000.0      1500\n",
            "3  22000.0      1200\n",
            "4      NaN      3000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If the type hints is not specified for `apply`, it is expensive to infer the data type internally.\n",
            "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n",
            "<ipython-input-18-34ffc18322ff>:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  return data[0] + data[1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    21000.0\n",
            "1    27500.0\n",
            "2    31500.0\n",
            "3    23200.0\n",
            "4        NaN\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkByExamples.com\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df=spark.range(100)\n",
        "print(df.sample(0.06).collect())\n",
        "dfff=df.sample(0.06).collect()\n",
        "\n",
        "print(dfff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5_YU9rKm2v1",
        "outputId": "bb8d2b6b-19d4-49e4-bccb-755ab023f500"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(id=2), Row(id=3), Row(id=6), Row(id=7), Row(id=40), Row(id=70), Row(id=80), Row(id=88)]\n",
            "[Row(id=65), Row(id=67)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkByExamples.com\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "filePath=\"small_zipcode.csv\"\n",
        "df = spark.read.options(header='true', inferSchema='true') \\\n",
        "          .csv(filePath)\n",
        "\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-9dcvKSokok",
        "outputId": "012efb30-8bb3-42f4-b1a0-b23d97da0425"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- zipcode: integer (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- population: integer (nullable = true)\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|id |zipcode|type    |city               |state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|1  |704    |STANDARD|NULL               |PR   |30100     |\n",
            "|2  |704    |NULL    |PASEO COSTA DEL SUR|PR   |NULL      |\n",
            "|3  |709    |NULL    |BDA SAN LUIS       |PR   |3700      |\n",
            "|4  |76166  |UNIQUE  |CINGULAR WIRELESS  |TX   |84000     |\n",
            "|5  |76177  |STANDARD|NULL               |TX   |NULL      |\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path= os.getcwd()\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HykqzCPSopIz",
        "outputId": "d5c3058d-5d7c-4a4e-b12d-df6a80904b5d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(value=0).show()\n",
        "df.fillna(value=0,subset=[\"population\"]).show()\n",
        "df.na.fill(value=0).show()\n",
        "df.na.fill(value=0,subset=[\"population\"]).show()\n",
        "\n",
        "\n",
        "df.fillna(value=\"\").show()\n",
        "df.na.fill(value=\"\").show()\n",
        "\n",
        "df.fillna(\"unknown\",[\"city\"]) \\\n",
        "    .fillna(\"\",[\"type\"]).show()\n",
        "\n",
        "df.fillna({\"city\": \"unknown\", \"type\": \"\"}) \\\n",
        "    .show()\n",
        "\n",
        "df.na.fill(\"unknown\",[\"city\"]) \\\n",
        "    .na.fill(\"\",[\"type\"]).show()\n",
        "\n",
        "df.na.fill({\"city\": \"unknown\", \"type\": \"\"}) \\\n",
        "    .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6n_cSLjqLbB",
        "outputId": "7fd062de-5916-4dc4-f5b0-d2b05ecf10ac"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               NULL|   PR|     30100|\n",
            "|  2|    704|    NULL|PASEO COSTA DEL SUR|   PR|         0|\n",
            "|  3|    709|    NULL|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               NULL|   TX|         0|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               NULL|   PR|     30100|\n",
            "|  2|    704|    NULL|PASEO COSTA DEL SUR|   PR|         0|\n",
            "|  3|    709|    NULL|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               NULL|   TX|         0|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               NULL|   PR|     30100|\n",
            "|  2|    704|    NULL|PASEO COSTA DEL SUR|   PR|         0|\n",
            "|  3|    709|    NULL|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               NULL|   TX|         0|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|               NULL|   PR|     30100|\n",
            "|  2|    704|    NULL|PASEO COSTA DEL SUR|   PR|         0|\n",
            "|  3|    709|    NULL|       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|               NULL|   TX|         0|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|                   |   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      NULL|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|                   |   TX|      NULL|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|                   |   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      NULL|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|                   |   TX|      NULL|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      NULL|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|            unknown|   TX|      NULL|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      NULL|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|            unknown|   TX|      NULL|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      NULL|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|            unknown|   TX|      NULL|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "| id|zipcode|    type|               city|state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|  1|    704|STANDARD|            unknown|   PR|     30100|\n",
            "|  2|    704|        |PASEO COSTA DEL SUR|   PR|      NULL|\n",
            "|  3|    709|        |       BDA SAN LUIS|   PR|      3700|\n",
            "|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n",
            "|  5|  76177|STANDARD|            unknown|   TX|      NULL|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "\n",
        "df.na.drop().show(truncate=False)\n",
        "\n",
        "df.na.drop(how=\"any\").show(truncate=False)\n",
        "\n",
        "df.na.drop(subset=[\"population\",\"type\"]) \\\n",
        "   .show(truncate=False)\n",
        "\n",
        "df.dropna().show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0pLcTUdtgRp",
        "outputId": "82d5b121-3f9b-402e-d9a0-5b4f7e34ec99"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: integer (nullable = true)\n",
            " |-- zipcode: integer (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- population: integer (nullable = true)\n",
            "\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|id |zipcode|type    |city               |state|population|\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "|1  |704    |STANDARD|NULL               |PR   |30100     |\n",
            "|2  |704    |NULL    |PASEO COSTA DEL SUR|PR   |NULL      |\n",
            "|3  |709    |NULL    |BDA SAN LUIS       |PR   |3700      |\n",
            "|4  |76166  |UNIQUE  |CINGULAR WIRELESS  |TX   |84000     |\n",
            "|5  |76177  |STANDARD|NULL               |TX   |NULL      |\n",
            "+---+-------+--------+-------------------+-----+----------+\n",
            "\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|id |zipcode|type  |city             |state|population|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|4  |76166  |UNIQUE|CINGULAR WIRELESS|TX   |84000     |\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|id |zipcode|type  |city             |state|population|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|4  |76166  |UNIQUE|CINGULAR WIRELESS|TX   |84000     |\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "|id |zipcode|type    |city             |state|population|\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "|1  |704    |STANDARD|NULL             |PR   |30100     |\n",
            "|4  |76166  |UNIQUE  |CINGULAR WIRELESS|TX   |84000     |\n",
            "+---+-------+--------+-----------------+-----+----------+\n",
            "\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|id |zipcode|type  |city             |state|population|\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "|4  |76166  |UNIQUE|CINGULAR WIRELESS|TX   |84000     |\n",
            "+---+-------+------+-----------------+-----+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "#Create spark session\n",
        "data = [(\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"), \\\n",
        "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"), \\\n",
        "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"), \\\n",
        "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")]\n",
        "\n",
        "columns= [\"Product\",\"Amount\",\"Country\"]\n",
        "df = spark.createDataFrame(data = data, schema = columns)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dk1WHsBqN9W",
        "outputId": "3f8a8e56-8406-4982-e3ee-75948a43ab31"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Amount: long (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+-------+------+-------+\n",
            "|Product|Amount|Country|\n",
            "+-------+------+-------+\n",
            "|Banana |1000  |USA    |\n",
            "|Carrots|1500  |USA    |\n",
            "|Beans  |1600  |USA    |\n",
            "|Orange |2000  |USA    |\n",
            "|Orange |2000  |USA    |\n",
            "|Banana |400   |China  |\n",
            "|Carrots|1200  |China  |\n",
            "|Beans  |1500  |China  |\n",
            "|Orange |4000  |China  |\n",
            "|Banana |2000  |Canada |\n",
            "|Carrots|2000  |Canada |\n",
            "|Beans  |2000  |Mexico |\n",
            "+-------+------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying pivot()\n",
        "pivotDF = df.groupBy(\"Product\").pivot(\"Country\").sum(\"Amount\")\n",
        "pivotDF.printSchema()\n",
        "pivotDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkjw8T8AzK4L",
        "outputId": "fdf14b14-bfa6-47ca-dfec-9ef7a54364be"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Canada: long (nullable = true)\n",
            " |-- China: long (nullable = true)\n",
            " |-- Mexico: long (nullable = true)\n",
            " |-- USA: long (nullable = true)\n",
            "\n",
            "+-------+------+-----+------+----+\n",
            "|Product|Canada|China|Mexico|USA |\n",
            "+-------+------+-----+------+----+\n",
            "|Orange |NULL  |4000 |NULL  |4000|\n",
            "|Beans  |NULL  |1500 |2000  |1600|\n",
            "|Banana |2000  |400  |NULL  |1000|\n",
            "|Carrots|2000  |1200 |NULL  |1500|\n",
            "+-------+------+-----+------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "unpivotExpr = \"stack(3, 'Canada', Canada, 'China', China, 'Mexico', Mexico) as (Country,Total)\"\n",
        "unPivotDF = pivotDF.select(\"Product\", expr(unpivotExpr)) \\\n",
        "    .where(\"Total is not null\")\n",
        "unPivotDF.show(truncate=False)\n",
        "unPivotDF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq3PzZXa0JCd",
        "outputId": "0172565f-f592-45da-f747-9a9bf31105ca"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+\n",
            "|Product|Country|Total|\n",
            "+-------+-------+-----+\n",
            "|Orange |China  |4000 |\n",
            "|Beans  |China  |1500 |\n",
            "|Beans  |Mexico |2000 |\n",
            "|Banana |Canada |2000 |\n",
            "|Banana |China  |400  |\n",
            "|Carrots|Canada |2000 |\n",
            "|Carrots|China  |1200 |\n",
            "+-------+-------+-----+\n",
            "\n",
            "+-------+-------+-----+\n",
            "|Product|Country|Total|\n",
            "+-------+-------+-----+\n",
            "| Orange|  China| 4000|\n",
            "|  Beans|  China| 1500|\n",
            "|  Beans| Mexico| 2000|\n",
            "| Banana| Canada| 2000|\n",
            "| Banana|  China|  400|\n",
            "|Carrots| Canada| 2000|\n",
            "|Carrots|  China| 1200|\n",
            "+-------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame by reading CSV file\n",
        "df=spark.read.option(\"header\",True) \\\n",
        "        .csv(\"simple-zipcodes.csv\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIotb6uS1Nz9",
        "outputId": "5c599c88-d82e-4433-ae68-474f09bd1867"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- RecordNumber: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Zipcode: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.option(\"header\",True) \\\n",
        "        .partitionBy(\"state\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .csv(\"zipcodes-state\")"
      ],
      "metadata": {
        "id": "E-VqqvyX5N7L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#partitionBy() multiple columns\n",
        "df.write.option(\"header\",True) \\\n",
        "        .partitionBy(\"state\",\"city\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .csv(\"zipcodes-state\")"
      ],
      "metadata": {
        "id": "EKdeT35Z5uGc"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.repartition(2).write.option(\"header\",True) \\\n",
        "        .partitionBy(\"state\") \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .csv(\"zipcodes-state\")"
      ],
      "metadata": {
        "id": "XaVLXtBY6Bai"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parq= spark.read.option(\"header\",True).csv(\"zipcodes-state\")\n",
        "parq.createOrReplaceTempView(\"Zipcode\")\n",
        "spark.sql(\"select * from Zipcode where state ='AL'\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X361Bly97qr_",
        "outputId": "1cd7b357-be91-495b-8fc4-01ecc6b46c38"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+-------------+-------+-----+\n",
            "|RecordNumber|Country|         City|Zipcode|state|\n",
            "+------------+-------+-------------+-------+-----+\n",
            "|       54355|     US|  SPRINGVILLE|  35146|   AL|\n",
            "|       54356|     US|  SPRUCE PINE|  35585|   AL|\n",
            "|       54354|     US|SPRING GARDEN|  36275|   AL|\n",
            "+------------+-------+-------------+-------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbGYSefnyvxkMYB+yWtraO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}